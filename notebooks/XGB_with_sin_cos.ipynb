{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from helper import DateToOrdinal\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "filename = \"train.csv\"\n",
    "df = pd.read_csv(os.path.join(\"..\", data_folder, filename))\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "test_cols_plus_y = [\"orders\", \"warehouse\", \"date\", \"holiday_name\", \"holiday\", \"shops_closed\", \"winter_school_holidays\", \"school_holidays\", \"id\"]\n",
    "df = df[test_cols_plus_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical columns\n",
    "df = df.drop(columns=[\"holiday_name\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "def create_lagged_features(df_l, value, lags):\n",
    "    for lag in range(1, lags + 1):\n",
    "        df_l[f't-{lag}'] = df_l[value].shift(lag)\n",
    "    df_l.dropna(inplace=True)\n",
    "    return df_l\n",
    "\n",
    "def add_cyclic_sin_cos_features(df_c, datecolumn = \"date\"):\n",
    "    # Create sin and cos features for day of year\n",
    "    df_c['dayofyear_sin'] = np.sin(2 * np.pi * df_c[datecolumn].dt.dayofyear/365.25)\n",
    "    df_c['dayofyear_cos'] = np.cos(2 * np.pi * df_c[datecolumn].dt.dayofyear/365.25)\n",
    "\n",
    "    # Create sin and cos features for day of week\n",
    "    df_c['dayofweek_sin'] = np.sin(2 * np.pi * df_c[datecolumn].dt.dayofweek/7)\n",
    "    df_c['dayofweek_cos'] = np.cos(2 * np.pi * df_c[datecolumn].dt.dayofweek/7)\n",
    "\n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_xgb(data):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        data = data.set_index(\"date\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
    "    xgb_pipe = make_pipeline(xgb_regressor)\n",
    "\n",
    "    warehouses = data[\"warehouse\"].unique().tolist()\n",
    "\n",
    "    for warehouse in warehouses:\n",
    "        warehouse_data = data[data[\"warehouse\"] == warehouse]\n",
    "\n",
    "        warehouse_data_X = warehouse_data.drop(columns=[\"orders\", \"warehouse\"])\n",
    "        warehouse_data_y = warehouse_data[\"orders\"]\n",
    "\n",
    "        final_score = abs(cross_val_score(xgb_pipe, warehouse_data_X, warehouse_data_y, cv=5, scoring=\"neg_mean_absolute_percentage_error\").mean())\n",
    "\n",
    "        result_list.append(final_score)\n",
    "        #print(warehouse, final_score)\n",
    "\n",
    "    print(np.mean(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1625589391568169\n"
     ]
    }
   ],
   "source": [
    "# just the raw data\n",
    "cross_val_xgb(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4927/242619256.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"daterange\"] = list(range(len(df)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14908633671881769\n"
     ]
    }
   ],
   "source": [
    "subset_df = df[[\"orders\", \"date\", \"warehouse\"]]\n",
    "subset_df[\"daterange\"] = list(range(len(df)))\n",
    "cross_val_xgb(subset_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged = create_lagged_features(df.copy(), \"orders\", lags=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09187430341703094\n"
     ]
    }
   ],
   "source": [
    "# Added only lagged features\n",
    "cross_val_xgb(df_lagged.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09359299352999409\n"
     ]
    }
   ],
   "source": [
    "df_lagged[\"daterange\"] = list(range(len(df_lagged)))\n",
    "# Added lagged + timesteps\n",
    "cross_val_xgb(df_lagged.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16391978845647534\n"
     ]
    }
   ],
   "source": [
    "# Added only cyclic features\n",
    "df_sin_cos = add_cyclic_sin_cos_features(df.copy(), datecolumn = \"date\")\n",
    "cross_val_xgb(df_sin_cos.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08275420684864583\n"
     ]
    }
   ],
   "source": [
    "# all together\n",
    "final_df = add_cyclic_sin_cos_features(df.copy(), datecolumn = \"date\")\n",
    "final_df = create_lagged_features(final_df.copy(), \"orders\", lags=14)\n",
    "final_df[\"daterange\"] = list(range(len(final_df)))\n",
    "cross_val_xgb(final_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7326, 26)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_holidays           7.035237e-03\n",
      "shops_closed              1.078186e-02\n",
      "holiday                   2.650912e-02\n",
      "winter_school_holidays    2.907835e-02\n",
      "orders                    4.764093e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df' is your DataFrame\n",
    "df_without_cat = df.drop(columns=[\"warehouse\", \"date\"])\n",
    "# Calculate variance for each feature\n",
    "variances = df_without_cat.var()\n",
    "\n",
    "# Sort features by variance\n",
    "sorted_variances = variances.sort_values()\n",
    "\n",
    "# Print features with lowest variance\n",
    "print(sorted_variances.head(10))\n",
    "\n",
    "# Optionally, set a threshold and remove low-variance features\n",
    "threshold = 0.01  # adjust as needed\n",
    "low_variance_features = sorted_variances[sorted_variances < threshold].index\n",
    "df_filtered = df.drop(columns=low_variance_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08413312334555127\n"
     ]
    }
   ],
   "source": [
    "# all together with filtered df\n",
    "final_df = add_cyclic_sin_cos_features(df_filtered.copy(), datecolumn = \"date\")\n",
    "final_df = create_lagged_features(final_df.copy(), \"orders\", lags=14)\n",
    "final_df[\"daterange\"] = list(range(len(final_df)))\n",
    "cross_val_xgb(final_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "def randomized_hyper_tuning(model, X, y):\n",
    "    # Define the parameter distribution\n",
    "    param_dist = {\n",
    "        'xgbregressor__learning_rate': uniform(0.009, 0.1),\n",
    "        'xgbregressor__n_estimators': randint(100, 600),\n",
    "        'xgbregressor__max_depth': randint(3, 8),\n",
    "        'xgbregressor__min_child_weight': randint(2, 6),\n",
    "        'xgbregressor__gamma': uniform(0, 0.2),\n",
    "    }\n",
    "\n",
    "    # Set up the RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=100,  # Number of parameter settings that are sampled\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_percentage_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X, y)\n",
    "    print(random_search.best_score_)\n",
    "    print(random_search.best_params_)\n",
    "\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_xgb_with_rand(data):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        data = data.set_index(\"date\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
    "    xgb_pipe = make_pipeline(xgb_regressor)\n",
    "\n",
    "    warehouses = data[\"warehouse\"].unique().tolist()\n",
    "\n",
    "    for warehouse in warehouses:\n",
    "        warehouse_data = data[data[\"warehouse\"] == warehouse]\n",
    "\n",
    "        warehouse_data_X = warehouse_data.drop(columns=[\"orders\", \"warehouse\"])\n",
    "        warehouse_data_y = warehouse_data[\"orders\"]\n",
    "\n",
    "        the_model = randomized_hyper_tuning(xgb_pipe, warehouse_data_X, warehouse_data_y)\n",
    "\n",
    "        final_score = abs(cross_val_score(the_model, warehouse_data_X, warehouse_data_y, cv=5, scoring=\"neg_mean_absolute_percentage_error\").mean())\n",
    "\n",
    "        result_list.append(final_score)\n",
    "        #print(warehouse, final_score)\n",
    "\n",
    "    print(np.mean(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_xgb_with_prophet(data):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        data = data.set_index(\"date\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
    "    xgb_pipe = make_pipeline(xgb_regressor)\n",
    "\n",
    "    warehouses = data[\"warehouse\"].unique().tolist()\n",
    "\n",
    "    for warehouse in warehouses:\n",
    "        warehouse_data = data[data[\"warehouse\"] == warehouse]\n",
    "\n",
    "        warehouse_data_X = warehouse_data.drop(columns=[\"orders\", \"warehouse\"])\n",
    "        warehouse_data_y = warehouse_data[\"orders\"]\n",
    "\n",
    "        the_model = randomized_hyper_tuning(xgb_pipe, warehouse_data_X, warehouse_data_y)\n",
    "\n",
    "        final_score = abs(cross_val_score(the_model, warehouse_data_X, warehouse_data_y, cv=5, scoring=\"neg_mean_absolute_percentage_error\").mean())\n",
    "\n",
    "        result_list.append(final_score)\n",
    "        #print(warehouse, final_score)\n",
    "\n",
    "    print(np.mean(result_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
